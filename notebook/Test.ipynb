{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Historian Data Processing\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------+-----+----------+\n",
      "|created_at           |tag_id  |value|confidence|\n",
      "+---------------------+--------+-----+----------+\n",
      "|2016-12-05 04:24:52.0|32000000|70.0 |0.0       |\n",
      "|2016-12-05 04:24:52.0|33000000|80.0 |0.0       |\n",
      "|2016-12-05 04:24:52.0|34000000|68.0 |0.0       |\n",
      "|2016-12-05 04:24:52.0|41000000|57.0 |0.0       |\n",
      "|2016-12-05 04:24:52.0|42000000|90.0 |0.0       |\n",
      "|2016-12-05 04:24:52.0|43000000|69.0 |0.0       |\n",
      "|2016-12-05 04:24:52.0|44000000|83.0 |0.0       |\n",
      "|2016-12-05 04:24:52.0|51000000|76.0 |0.0       |\n",
      "|2016-12-05 04:24:52.0|52000000|78.0 |0.0       |\n",
      "|2016-12-05 04:24:52.0|53000000|66.0 |0.0       |\n",
      "|2016-12-05 04:24:52.0|54000000|65.0 |0.0       |\n",
      "|2016-12-05 04:24:52.0|61000000|80.0 |0.0       |\n",
      "|2016-12-05 04:24:52.0|62000000|62.0 |0.0       |\n",
      "|2016-12-05 04:24:52.0|63000000|70.0 |0.0       |\n",
      "|2016-12-05 04:24:52.0|64000000|55.0 |0.0       |\n",
      "|2016-12-05 04:24:52.0|71000000|70.0 |0.0       |\n",
      "|2016-12-05 04:24:52.0|72000000|85.0 |0.0       |\n",
      "|2016-12-05 04:24:52.0|73000000|85.0 |0.0       |\n",
      "|2016-12-05 04:24:52.0|74000000|88.0 |0.0       |\n",
      "|2016-12-05 04:24:52.0|81000000|56.0 |0.0       |\n",
      "+---------------------+--------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType, TimestampType, DoubleType, StructField, StructType\n",
    "fields = [StructField('created_at', TimestampType(), True),\n",
    "          StructField('tag_id', IntegerType(), True),\n",
    "          StructField('value', DoubleType(), True),\n",
    "          StructField('confidence', DoubleType(), True)]\n",
    "\n",
    "df = spark.read.csv(\"/Users/samir/Box Sync/Cloudera/Demos/cdh_historian/sample_data\", \n",
    "                    schema=StructType(fields), \n",
    "                    timestampFormat='yyyy-MM-dd HH:mm:ss')\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
      "|          created_at|11000000|12000000|13000000|14000000|21000000|22000000|23000000|24000000|\n",
      "+--------------------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
      "|2016-12-05 14:23:...|    97.0|    81.0|    76.0|    65.0|    94.0|    74.0|    59.0|    65.0|\n",
      "|2016-12-05 07:43:...|    85.0|    93.0|    98.0|    84.0|    88.0|    98.0|    58.0|    80.0|\n",
      "|2016-12-05 05:06:...|    92.0|    80.0|    98.0|    87.0|    85.0|    77.0|    95.0|    67.0|\n",
      "|2016-12-05 07:05:...|    65.0|    55.0|    80.0|    57.0|    58.0|    62.0|    69.0|    88.0|\n",
      "|2016-12-05 10:24:...|    61.0|    71.0|    74.0|    51.0|    56.0|    67.0|    71.0|    71.0|\n",
      "|2016-12-05 13:31:...|    96.0|    68.0|    68.0|    77.0|    85.0|    81.0|    57.0|    96.0|\n",
      "|2016-12-05 14:55:...|    77.0|    92.0|    97.0|    92.0|    53.0|    80.0|    88.0|    80.0|\n",
      "|2016-12-05 11:27:...|    82.0|    94.0|    93.0|    87.0|    57.0|    76.0|    71.0|    87.0|\n",
      "|2016-12-05 13:04:...|    60.0|    88.0|    78.0|    78.0|    53.0|    93.0|    89.0|    78.0|\n",
      "|2016-12-05 13:38:...|    56.0|    89.0|    67.0|    84.0|    84.0|    50.0|    86.0|    50.0|\n",
      "|2016-12-05 12:21:...|    93.0|    57.0|    95.0|    87.0|    50.0|    96.0|    70.0|    78.0|\n",
      "|2016-12-05 07:59:...|    77.0|    50.0|    96.0|    72.0|    53.0|    97.0|    83.0|    79.0|\n",
      "|2016-12-05 09:07:...|    61.0|    69.0|    78.0|    66.0|    82.0|    59.0|    74.0|    91.0|\n",
      "|2016-12-05 07:23:...|    59.0|    50.0|    56.0|    64.0|    84.0|    96.0|    80.0|    61.0|\n",
      "|2016-12-05 13:57:...|    74.0|    97.0|    87.0|    84.0|    87.0|    73.0|    55.0|    52.0|\n",
      "|2016-12-05 07:24:...|    59.0|    52.0|    91.0|    91.0|    82.0|    63.0|    57.0|    54.0|\n",
      "|2016-12-05 05:07:...|    80.0|    90.0|    99.0|    74.0|    60.0|    94.0|    50.0|    52.0|\n",
      "|2016-12-05 10:31:...|    70.0|    84.0|    50.0|    61.0|    80.0|    80.0|    83.0|    74.0|\n",
      "|2016-12-05 11:01:...|    72.0|    67.0|    59.0|    87.0|    84.0|    84.0|    82.0|    98.0|\n",
      "|2016-12-05 10:22:...|    52.0|    71.0|    71.0|    69.0|    77.0|    76.0|    52.0|    56.0|\n",
      "+--------------------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pivot_df = df.filter('tag_id<30000000').groupby('created_at').pivot('tag_id').agg(sum('value'))\n",
    "pivot_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- created_at: timestamp (nullable = true)\n",
      " |-- 11000000: double (nullable = true)\n",
      " |-- 12000000: double (nullable = true)\n",
      " |-- 13000000: double (nullable = true)\n",
      " |-- 14000000: double (nullable = true)\n",
      " |-- 21000000: double (nullable = true)\n",
      " |-- 22000000: double (nullable = true)\n",
      " |-- 23000000: double (nullable = true)\n",
      " |-- 24000000: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pivot_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
